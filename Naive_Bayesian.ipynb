{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']\n",
    "    data = np.array(df.iloc[:100, :])\n",
    "    # print(data)\n",
    "    return data[:,:-1], data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Naive_Bayes:\n",
    "    def __init__(self):\n",
    "        self.model=None\n",
    "    \n",
    "    def mean(self, X):\n",
    "        return np.mean(X)\n",
    "\n",
    "    def stdev(self, X):       \n",
    "        return np.std(X)\n",
    "        \n",
    "\n",
    "    def gaussian_prob(self, x, mean, stdev):\n",
    "        exponent = math.exp(-(math.pow(x - mean, 2) / \n",
    "                              (2 * math.pow(stdev, 2))))\n",
    "        Prob=  (1 / (math.sqrt(2 * math.pi) * stdev))*exponent\n",
    "        return Prob\n",
    "\n",
    "    def summarize(self, train_data):\n",
    "        summaries=[(np.mean(i), np.std(i)) for i in zip(*train_data)]\n",
    "        return summaries\n",
    "    \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        labels=list(set(y))\n",
    "        data={label:[] for label in labels}\n",
    "\n",
    "        for f, label in zip(X,y):\n",
    "            data[label].append(f)\n",
    "        self.model={\n",
    "            label:self.summarize(value)\n",
    "            for label, value in data.items()\n",
    "        }    \n",
    "        print('Model fitting is done')\n",
    "        \n",
    "\n",
    "    def calculate_prob(self, input_data):\n",
    "        prob={}\n",
    "        for label, value in self.model.items():\n",
    "            prob[label]=1   #since all the categories have the same numbers\n",
    "            for i in range(len(value)):\n",
    "                mean, stdev= value[i]\n",
    "                prob[label] *=self.gaussian_prob(\n",
    "                    input_data[i], mean, stdev\n",
    "                )\n",
    "\n",
    "        return prob\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # {0.0: 2.9680340789325763e-27, 1.0: 3.5749783019849535e-26}\n",
    "        label = sorted(\n",
    "            self.calculate_prob(X_test).items(),\n",
    "            key=lambda x: x[-1])[-1][0]\n",
    "        return label\n",
    "\n",
    "        pass\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        right = 0\n",
    "        for X, y in zip(X_test, y_test):\n",
    "            label = self.predict(X)\n",
    "            if label == y:\n",
    "                right += 1\n",
    "\n",
    "        return right / float(len(X_test))\n",
    "        pass\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model fitting is done\n"
    }
   ],
   "source": [
    "NB=Naive_Bayes()\n",
    "NB.fit(X_train, y_train)\n",
    "#NB.summarize(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{0.0: [(4.965000000000001, 0.3275286247032464),\n  (3.3875, 0.36618813470673783),\n  (1.4849999999999999, 0.16209565077447327),\n  (0.2425, 0.10461237976453838)],\n 1.0: [(5.97, 0.49742671151973067),\n  (2.8133333333333335, 0.25655841873191815),\n  (4.3, 0.48373546489791297),\n  (1.3366666666666664, 0.19232495649002207)]}"
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB.model"
   ]
  }
 ]
}